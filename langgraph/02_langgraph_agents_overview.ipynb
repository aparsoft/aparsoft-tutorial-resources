{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127a80d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LangGraph - Complete Implementation Guide\n",
    "\n",
    "## Overview\n",
    "\n",
    "**LangGraph** is a low-level orchestration framework for building, managing, and deploying long-running, stateful AI agents. Released as version 1.0 in October 2025, it provides the infrastructure for building production-ready agent systems with comprehensive memory, human-in-the-loop capabilities, and durable execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc7021",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [What's New in LangChain v0.3](#whats-new-in-langchain-v3)\n",
    "2. [Architecture Changes](#architecture-changes)\n",
    "3. [Package Structure](#package-structure)\n",
    "4. [Migration Guide](#migration-guide)\n",
    "5. [Key Features](#key-features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfae0b6",
   "metadata": {},
   "source": [
    "### Core Changes\n",
    "\n",
    "**1. Agent Implementation on LangGraph**\n",
    "- The new `create_agent` implementation is built on top of LangGraph\n",
    "- Takes advantage of the underlying agent runtime\n",
    "- Same high-level interface, different underpinning\n",
    "- Battle-tested in production by companies like Uber, LinkedIn, and Klarna\n",
    "\n",
    "**2. Pydantic 2 Migration**\n",
    "- Full upgrade from Pydantic 1 to Pydantic 2 internally\n",
    "- Pydantic 1 support dropped (reached end-of-life June 2024)\n",
    "- No need for bridges like `langchain_core.pydantic_v1`\n",
    "\n",
    "**3. Python Version Requirements**\n",
    "- Python 3.8 no longer supported (end-of-life October 2024)\n",
    "- Minimum Python version: 3.9+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9dd280",
   "metadata": {},
   "source": [
    "## Core Concepts\n",
    "\n",
    "### What is LangGraph?\n",
    "\n",
    "LangGraph provides:\n",
    "\n",
    "1. **Durable Execution**: Agents persist through failures and resume automatically\n",
    "2. **Human-in-the-Loop**: Inspect and modify agent state at any point\n",
    "3. **Comprehensive Memory**: Short-term and long-term persistent memory\n",
    "4. **Stateful Workflows**: Build complex, stateful agent architectures\n",
    "5. **Production-Ready**: Scalable infrastructure for production deployment\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "```bash\n",
    "# LangGraph doesn't abstract prompts or architecture\n",
    "# You have full control over:\n",
    "- Agent decision-making logic\n",
    "- State management\n",
    "- Tool calling patterns\n",
    "- Memory strategies\n",
    "- Human intervention points\n",
    "```\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "# Basic installation\n",
    "pip install langgraph\n",
    "\n",
    "# With checkpointing support\n",
    "pip install langgraph langgraph-checkpoint-postgres\n",
    "\n",
    "# Full installation with extras\n",
    "pip install \"langgraph[postgres]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30ee70",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "### Graph-Based Design\n",
    "\n",
    "LangGraph uses a graph structure where:\n",
    "- **Nodes** represent processing steps (functions)\n",
    "- **Edges** represent data flow between nodes\n",
    "- **State** is shared across all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572e798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a secret openai key input in jupyter notebook\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Securely input OpenAI API key\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b800ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='63401bb9-094b-45b7-8fa7-fc550828e275'),\n",
       "  AIMessage(content='hello world', additional_kwargs={}, response_metadata={}, id='b25b4f39-7932-48e6-ab03-83f255cf5ad9')]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "\n",
    "\n",
    "def mock_llm(state: MessagesState):\n",
    "    return {\"messages\": [{\"role\": \"ai\", \"content\": \"hello world\"}]}\n",
    "\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(mock_llm)\n",
    "graph.add_edge(START, \"mock_llm\")\n",
    "graph.add_edge(\"mock_llm\", END)\n",
    "graph = graph.compile()\n",
    "\n",
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37c8f4",
   "metadata": {},
   "source": [
    "### Step 0: Define tools and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10ed61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"openai:o4-mini\")\n",
    "\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# Augment the LLM with tools\n",
    "tools = [add, multiply, divide]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822df671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': StructuredTool(name='add', description='Adds a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x7c5cfe81ba60>),\n",
       " 'multiply': StructuredTool(name='multiply', description='Multiply a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x7c5cffa92ac0>),\n",
       " 'divide': StructuredTool(name='divide', description='Divide a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int', args_schema=<class 'langchain_core.utils.pydantic.divide'>, func=<function divide at 0x7c5cfe7eb740>)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afceb4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7c5cfed87410>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7c5cfe80bd40>, root_client=<openai.OpenAI object at 0x7c5cff659fa0>, root_async_client=<openai.AsyncOpenAI object at 0x7c5cfec6de20>, model_name='o4-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'add', 'description': 'Adds a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiply a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'divide', 'description': 'Divide a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64f835",
   "metadata": {},
   "source": [
    "### Step 1: Define state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60225916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    llm_calls: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c9876",
   "metadata": {},
   "source": [
    "### Step 2: Define model node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d9e7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "\n",
    "def llm_call(state: dict):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ],\n",
    "        \"llm_calls\": state.get(\"llm_calls\", 0) + 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485d9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = llm_call({\"messages\": [{\"role\": \"user\", \"content\": \"What is north?\"}]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1e32e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='North is one of the four primary (cardinal) compass directions. Here are a few ways to think about it:\\n\\n1. Geographic North  \\n   – It points toward Earth’s North Pole, the point where the planet’s axis of rotation meets its surface in the Northern Hemisphere.  \\n   – On most maps (in Western cartography), north is oriented “up.”  \\n\\n2. Magnetic North  \\n   – A compass needle actually aligns with Earth’s magnetic field, pointing toward what’s called Magnetic North.  \\n   – Magnetic North moves slightly over time due to changes in Earth’s core.  \\n\\n3. Usage  \\n   – Navigation: “Head north” means to travel toward higher latitudes (toward the Pole).  \\n   – Orientation: If you stand facing north, east will be on your right, west on your left, and south directly behind you.  \\n\\nIn everyday life, knowing where north is lets you orient maps, plan routes, and understand how the Sun’s path changes with the seasons (it rises generally in the east and sets in the west, arcing across southern skies in the Northern Hemisphere).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 306, 'prompt_tokens': 150, 'total_tokens': 456, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o4-mini-2025-04-16', 'system_fingerprint': None, 'id': 'chatcmpl-CMDvrRy4NcvclUNquKLxkGF3kpk8z', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1453ef31-7672-4899-84e8-754a9d87e4c1-0', usage_metadata={'input_tokens': 150, 'output_tokens': 306, 'total_tokens': 456, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})],\n",
       " 'llm_calls': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea9eb6",
   "metadata": {},
   "source": [
    "### Step 3: Define tool node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8fb5113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c1aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node({\"messages\": ans[\"messages\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf59974",
   "metadata": {},
   "source": [
    "### Step 4: Define logic to determine whether to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acbce17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "# Conditional edge function to route to the tool node or end \n",
    "# based upon whether the LLM made a tool call\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a8afbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__end__'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "should_continue({\"messages\": ans[\"messages\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbf2449",
   "metadata": {},
   "source": [
    "### Step 5: Build agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c09b846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build workflow\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\"llm_call\", should_continue, [\"tool_node\", END])\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77fec09",
   "metadata": {},
   "source": [
    "### Visualize the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43830572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba08b2b",
   "metadata": {},
   "source": [
    "### Invoke the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "106fe5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_pAtRZOd2e9yhPNlnsM7m6AFz)\n",
      " Call ID: call_pAtRZOd2e9yhPNlnsM7m6AFz\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "messages = agent.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dedf232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'call_llm': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_RUW4Mx1inY2aQmgUP69mtYkE', 'function': {'arguments': '{\"a\":3,\"b\":4}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 153, 'total_tokens': 243, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o4-mini-2025-04-16', 'system_fingerprint': None, 'id': 'chatcmpl-CMDvzXhvRN8GidDbj4AfFL94c2uuS', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3bd9aec1-c168-4acc-a9ad-7ab28fa419b6-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 4}, 'id': 'call_RUW4Mx1inY2aQmgUP69mtYkE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 153, 'output_tokens': 90, 'total_tokens': 243, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})}\n",
      "\n",
      "\n",
      "{'call_tool': ToolMessage(content='7', name='add', tool_call_id='call_RUW4Mx1inY2aQmgUP69mtYkE')}\n",
      "\n",
      "\n",
      "{'call_llm': AIMessage(content='The sum of 3 and 4 is 7.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 184, 'total_tokens': 208, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o4-mini-2025-04-16', 'system_fingerprint': None, 'id': 'chatcmpl-CMDw2jjx7KSdSuYxymJ37NfgMHvNW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--37118f9e-6bdf-460a-9434-79d454ed9a2c-0', usage_metadata={'input_tokens': 184, 'output_tokens': 24, 'total_tokens': 208, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "\n",
      "\n",
      "{'agent': [HumanMessage(content='Add 3 and 4.', additional_kwargs={}, response_metadata={}, id='c2690201-ea8b-46f0-97f3-f0bc065eebfb'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_RUW4Mx1inY2aQmgUP69mtYkE', 'function': {'arguments': '{\"a\":3,\"b\":4}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 153, 'total_tokens': 243, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o4-mini-2025-04-16', 'system_fingerprint': None, 'id': 'chatcmpl-CMDvzXhvRN8GidDbj4AfFL94c2uuS', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3bd9aec1-c168-4acc-a9ad-7ab28fa419b6-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 4}, 'id': 'call_RUW4Mx1inY2aQmgUP69mtYkE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 153, 'output_tokens': 90, 'total_tokens': 243, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content='7', name='add', id='e3ab8037-3b04-43ca-9525-739f9abf067e', tool_call_id='call_RUW4Mx1inY2aQmgUP69mtYkE'), AIMessage(content='The sum of 3 and 4 is 7.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 184, 'total_tokens': 208, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o4-mini-2025-04-16', 'system_fingerprint': None, 'id': 'chatcmpl-CMDw2jjx7KSdSuYxymJ37NfgMHvNW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--37118f9e-6bdf-460a-9434-79d454ed9a2c-0', usage_metadata={'input_tokens': 184, 'output_tokens': 24, 'total_tokens': 208, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Define tools and model\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# Augment the LLM with tools\n",
    "tools = [add, multiply, divide]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "from langgraph.graph import add_messages\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    BaseMessage,\n",
    "    ToolCall,\n",
    ")\n",
    "from langgraph.func import entrypoint, task\n",
    "\n",
    "\n",
    "# Step 1: define model node\n",
    "@task\n",
    "def call_llm(messages: list[BaseMessage]):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "    return llm_with_tools.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "            )\n",
    "        ]\n",
    "        + messages\n",
    "    )\n",
    "\n",
    "\n",
    "# Step 2: define tool node\n",
    "@task\n",
    "def call_tool(tool_call: ToolCall):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "    tool = tools_by_name[tool_call[\"name\"]]\n",
    "    return tool.invoke(tool_call)\n",
    "\n",
    "\n",
    "# Step 3: define agent\n",
    "@entrypoint()\n",
    "def agent(messages: list[BaseMessage]):\n",
    "    llm_response = call_llm(messages).result()\n",
    "\n",
    "    while True:\n",
    "        if not llm_response.tool_calls:\n",
    "            break\n",
    "\n",
    "        # Execute tools\n",
    "        tool_result_futures = [\n",
    "            call_tool(tool_call) for tool_call in llm_response.tool_calls\n",
    "        ]\n",
    "        tool_results = [fut.result() for fut in tool_result_futures]\n",
    "        messages = add_messages(messages, [llm_response, *tool_results])\n",
    "        llm_response = call_llm(messages).result()\n",
    "\n",
    "    messages = add_messages(messages, llm_response)\n",
    "    return messages\n",
    "\n",
    "\n",
    "# Invoke\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "for chunk in agent.stream(messages, stream_mode=\"updates\"):\n",
    "    print(chunk)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
