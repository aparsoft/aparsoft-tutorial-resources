{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44351c1",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: flex-start; align-items: center; margin-bottom: 20px;\">\n",
    "    <img src=\"aparsoft-tutorial-resources/assets/icons/aparsoft_logo.png\" alt=\"Aparsoft Logo\" style=\"height: 60px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d207f",
   "metadata": {},
   "source": [
    "# LangGraph: Workflows vs Agents - Complete Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a20c15",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "LangGraph offers two fundamental approaches to building AI systems: **Workflows** and **Agents**. Understanding when to use each is critical for building efficient, maintainable AI applications.\n",
    "\n",
    "### The Fundamental Difference\n",
    "\n",
    "| Aspect | Workflows | Agents |\n",
    "|--------|-----------|--------|\n",
    "| **Control Flow** | Developer-defined | LLM-determined |\n",
    "| **Predictability** | High - predetermined paths | Lower - dynamic decisions |\n",
    "| **Complexity** | Simpler to debug | More complex reasoning |\n",
    "| **Use Case** | Known process steps | Open-ended problems |\n",
    "| **LLM Role** | Embedded in predefined steps | Orchestrates its own actions |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eb0475",
   "metadata": {},
   "source": [
    "## Core Concepts\n",
    "\n",
    "### What is a Workflow?\n",
    "\n",
    "A **workflow** is a graph where:\n",
    "- The control flow is **predetermined** by the developer\n",
    "- LLMs operate **within** the defined structure\n",
    "- Paths are **known at design time**\n",
    "- The system follows **explicit routing logic**\n",
    "\n",
    "```\n",
    "Input ‚Üí LLM Call ‚Üí  Gate ‚Üí        LLM Call ‚Üí Output\n",
    "        (fixed)     (conditional) (fixed)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c426c",
   "metadata": {},
   "source": [
    "### What is an Agent?\n",
    "\n",
    "An **agent** is a system where:\n",
    "- The LLM **decides** the control flow\n",
    "- Tools are available but **usage is dynamic**\n",
    "- The system **adapts** to environmental feedback\n",
    "- Paths emerge from **agent decisions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fced697",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "Input ‚Üí Agent decides ‚Üí Tool/Action ‚Üí Feedback ‚Üí Agent decides ‚Üí ... \n",
    "        (dynamic)       (variable)    (loop)     (dynamic)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bad2149",
   "metadata": {},
   "source": [
    "## Workflows Explained\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "1. **Predetermined Paths**: You define all possible routes\n",
    "2. **Embedded Intelligence**: LLMs enhance specific steps\n",
    "3. **Explicit Control**: Clear start, end, and decision points\n",
    "4. **Verifiable Stages**: Each step can be tested independently\n",
    "\n",
    "### Workflow Patterns\n",
    "\n",
    "#### 1. Prompt Chaining\n",
    "Sequential LLM calls where each processes the previous output.\n",
    "\n",
    "**When to Use:**\n",
    "- Translation with quality checks\n",
    "- Content generation with refinement\n",
    "- Multi-step verification processes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb8b4f",
   "metadata": {},
   "source": [
    "**Example Structure:**\n",
    "```python\n",
    "def workflow():\n",
    "    draft = llm_generate(input)\n",
    "    if quality_check(draft) == \"fail\":\n",
    "        draft = llm_improve(draft, feedback)\n",
    "    final = llm_polish(draft)\n",
    "    return final\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7334b3",
   "metadata": {},
   "source": [
    "#### 2. Parallelization\n",
    "Multiple independent LLM calls executing simultaneously.\n",
    "\n",
    "**When to Use:**\n",
    "- Processing multiple data sources\n",
    "- Generating varied content types\n",
    "- Independent analysis tasks\n",
    "\n",
    "**Example Structure:**\n",
    "```python\n",
    "def workflow(topic):\n",
    "    # Parallel execution\n",
    "    summary_future = llm_summarize(topic)\n",
    "    analysis_future = llm_analyze(topic)\n",
    "    keywords_future = llm_extract_keywords(topic)\n",
    "    \n",
    "    # Aggregate results\n",
    "    return combine(summary_future.result(), \n",
    "                   analysis_future.result(),\n",
    "                   keywords_future.result())\n",
    "```\n",
    "\n",
    "#### 3. Routing\n",
    "Directing inputs to specialized handlers based on classification.\n",
    "\n",
    "**When to Use:**\n",
    "- Customer service categorization\n",
    "- Document type processing\n",
    "- Multi-intent handling\n",
    "\n",
    "**Example Structure:**\n",
    "```python\n",
    "def workflow(query):\n",
    "    category = llm_classify(query)\n",
    "    \n",
    "    if category == \"technical\":\n",
    "        return technical_handler(query)\n",
    "    elif category == \"billing\":\n",
    "        return billing_handler(query)\n",
    "    else:\n",
    "        return general_handler(query)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76903419",
   "metadata": {},
   "source": [
    "#### 4. Orchestrator-Worker\n",
    "Orchestrator breaks down tasks and delegates to workers.\n",
    "\n",
    "**When to Use:**\n",
    "- Report generation with sections\n",
    "- Complex document processing\n",
    "- Multi-component analysis\n",
    "\n",
    "**Example Structure:**\n",
    "```python\n",
    "def workflow(task):\n",
    "    # Orchestrator plans\n",
    "    subtasks = orchestrator_plan(task)\n",
    "    \n",
    "    # Workers execute in parallel\n",
    "    results = [worker_execute(st) for st in subtasks]\n",
    "    \n",
    "    # Orchestrator synthesizes\n",
    "    return orchestrator_synthesize(results)\n",
    "```\n",
    "\n",
    "#### 5. Evaluator-Optimizer\n",
    "Generate-evaluate-refine loop until quality criteria met.\n",
    "\n",
    "**When to Use:**\n",
    "- Content meeting specific criteria\n",
    "- Iterative refinement tasks\n",
    "- Quality-gated outputs\n",
    "\n",
    "**Example Structure:**\n",
    "```python\n",
    "def workflow(requirements):\n",
    "    output = generator(requirements)\n",
    "    \n",
    "    while True:\n",
    "        evaluation = evaluator(output, requirements)\n",
    "        if evaluation.passed:\n",
    "            break\n",
    "        output = optimizer(output, evaluation.feedback)\n",
    "    \n",
    "    return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3eb36b",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687124c9",
   "metadata": {},
   "source": [
    "## Agents Explained\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "1. **Autonomous Decision-Making**: Agent chooses tools and actions\n",
    "2. **Dynamic Tool Usage**: Tools selected based on context\n",
    "3. **Feedback Loops**: Continuous observation-action cycles\n",
    "4. **Adaptive Behavior**: Responds to environmental changes\n",
    "\n",
    "### Agent Architecture\n",
    "\n",
    "```python\n",
    "# Core Agent Loop\n",
    "def agent(input):\n",
    "    state = initialize(input)\n",
    "    \n",
    "    while not is_complete(state):\n",
    "        # Agent decides next action\n",
    "        action = llm_decide(state, available_tools)\n",
    "        \n",
    "        # Execute action\n",
    "        result = execute_tool(action)\n",
    "        \n",
    "        # Update state with feedback\n",
    "        state = update_state(state, result)\n",
    "    \n",
    "    return state.final_answer\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234cdad7",
   "metadata": {},
   "source": [
    "### Agent Components\n",
    "\n",
    "#### 1. Tools\n",
    "Functions the agent can invoke:\n",
    "```python\n",
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    \"\"\"Search internal database for information.\"\"\"\n",
    "    return database.search(query)\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"Evaluate mathematical expression.\"\"\"\n",
    "    return eval(expression)\n",
    "```\n",
    "\n",
    "#### 2. Memory\n",
    "State that persists across agent decisions:\n",
    "```python\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    context: dict\n",
    "    tool_results: list\n",
    "    iterations: int\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed43fe1",
   "metadata": {},
   "source": [
    "#### 3. Decision Logic\n",
    "The agent's reasoning process:\n",
    "```python\n",
    "def agent_node(state):\n",
    "    # Agent sees state and available tools\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    \n",
    "    # Agent decides: answer or use tool\n",
    "    if response.tool_calls:\n",
    "        return {\"action\": \"use_tool\", \"tool_calls\": response.tool_calls}\n",
    "    else:\n",
    "        return {\"action\": \"respond\", \"response\": response}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa87b12",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6364502",
   "metadata": {},
   "source": [
    "## Decision Framework\n",
    "\n",
    "### Choose Workflows When:\n",
    "\n",
    "‚úÖ **Process is well-defined**\n",
    "- Steps are known in advance\n",
    "- Decision points are clear\n",
    "- Quality gates are explicit\n",
    "\n",
    "‚úÖ **Determinism is important**\n",
    "- Need consistent execution paths\n",
    "- Debugging requires clarity\n",
    "- Compliance requires auditability\n",
    "\n",
    "‚úÖ **Subtasks are independent**\n",
    "- Can parallelize operations\n",
    "- Each step is verifiable\n",
    "- Clear input-output contracts\n",
    "\n",
    "‚úÖ **Examples:**\n",
    "- Document translation pipeline\n",
    "- Report generation with sections\n",
    "- Multi-step content validation\n",
    "- Structured data processing\n",
    "\n",
    "### Choose Agents When:\n",
    "\n",
    "‚úÖ **Problem is open-ended**\n",
    "- Solution path unknown upfront\n",
    "- Requires exploration\n",
    "- Multiple valid approaches\n",
    "\n",
    "‚úÖ **Tool selection is dynamic**\n",
    "- Agent must choose appropriate tools\n",
    "- Context determines actions\n",
    "- Adaptive behavior needed\n",
    "\n",
    "‚úÖ **Iterative refinement required**\n",
    "- Feedback loops essential\n",
    "- Self-correction needed\n",
    "- Learning from attempts\n",
    "\n",
    "‚úÖ **Examples:**\n",
    "- Research assistants\n",
    "- Code debugging\n",
    "- Complex problem solving\n",
    "- Interactive troubleshooting\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b8c19",
   "metadata": {},
   "source": [
    "## Architecture Patterns\n",
    "\n",
    "### Hybrid Approach: Workflows with Agent Nodes\n",
    "\n",
    "Combine both paradigms for optimal results:\n",
    "\n",
    "```python\n",
    "def hybrid_system(input):\n",
    "    # Workflow structure\n",
    "    classified = routing_llm(input)\n",
    "    \n",
    "    if classified == \"simple\":\n",
    "        # Use workflow for simple cases\n",
    "        return simple_workflow(input)\n",
    "    else:\n",
    "        # Use agent for complex cases\n",
    "        return agent_system(input)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4e0a4",
   "metadata": {},
   "source": [
    "### Multi-Agent Workflows\n",
    "\n",
    "Orchestrate multiple specialized agents:\n",
    "\n",
    "```python\n",
    "def multi_agent_workflow(task):\n",
    "    # Orchestrator (workflow) coordinates agents\n",
    "    plan = orchestrator_plan(task)\n",
    "    \n",
    "    results = []\n",
    "    for subtask in plan:\n",
    "        # Each subtask handled by specialized agent\n",
    "        agent = select_agent(subtask.type)\n",
    "        result = agent.execute(subtask)\n",
    "        results.append(result)\n",
    "    \n",
    "    return synthesize(results)\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a116ea",
   "metadata": {},
   "source": [
    "## Real-World Use Cases\n",
    "\n",
    "### Workflow Use Cases\n",
    "\n",
    "#### 1. Content Localization Pipeline\n",
    "```\n",
    "Input (EN) ‚Üí Translate (LLM) ‚Üí Cultural Check (LLM) ‚Üí \n",
    "Quality Gate ‚Üí Refinement (if needed) ‚Üí Output (ES)\n",
    "```\n",
    "\n",
    "**Why Workflow:** Fixed stages, clear quality criteria, verifiable steps\n",
    "\n",
    "#### 2. Financial Report Generation\n",
    "```\n",
    "Data ‚Üí Section Analysis (Parallel LLMs) ‚Üí \n",
    "Orchestrator Combines ‚Üí Executive Summary ‚Üí Final Report\n",
    "```\n",
    "\n",
    "**Why Workflow:** Known report structure, parallel processing, deterministic output\n",
    "\n",
    "#### 3. Resume Screening System\n",
    "```\n",
    "Resume ‚Üí Extract Info (LLM) ‚Üí Category Router ‚Üí \n",
    "[Technical/Creative/Management] Handler ‚Üí Ranking\n",
    "```\n",
    "\n",
    "**Why Workflow:** Clear categorization, specialized processing, audit trail\n",
    "\n",
    "### Agent Use Cases\n",
    "\n",
    "#### 1. Research Assistant\n",
    "```\n",
    "Question ‚Üí Agent decides: [Search/Read/Synthesize] ‚Üí \n",
    "Evaluates completeness ‚Üí More research or Answer\n",
    "```\n",
    "\n",
    "**Why Agent:** Unknown information needs, dynamic tool selection, iterative refinement\n",
    "\n",
    "#### 2. Code Debugger\n",
    "```\n",
    "Bug Report ‚Üí Agent: [Read code/Run tests/Check logs] ‚Üí \n",
    "Hypothesis ‚Üí [Test/Verify] ‚Üí Solution or iterate\n",
    "```\n",
    "\n",
    "**Why Agent:** Unpredictable debugging path, adaptive strategy, tool choice depends on findings\n",
    "\n",
    "#### 3. Customer Support Bot\n",
    "```\n",
    "Query ‚Üí Agent: [Search KB/Check account/Escalate] ‚Üí \n",
    "Response ‚Üí Verify satisfaction ‚Üí Follow-up or close\n",
    "```\n",
    "\n",
    "**Why Agent:** Varied customer needs, context-dependent actions, learning from interactions\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34895d36",
   "metadata": {},
   "source": [
    "## Implementation Examples\n",
    "\n",
    "### Workflow Implementation (Evaluator-Optimizer)\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    task: str\n",
    "    output: str\n",
    "    feedback: str\n",
    "    iterations: int\n",
    "\n",
    "def generator(state: State):\n",
    "    result = llm.invoke(f\"Generate: {state['task']}\")\n",
    "    return {\"output\": result.content, \"iterations\": state.get(\"iterations\", 0) + 1}\n",
    "\n",
    "def evaluator(state: State):\n",
    "    evaluation = llm.invoke(f\"Evaluate: {state['output']} for task: {state['task']}\")\n",
    "    return {\"feedback\": evaluation.content}\n",
    "\n",
    "def should_continue(state: State):\n",
    "    if \"approved\" in state[\"feedback\"].lower() or state[\"iterations\"] >= 3:\n",
    "        return END\n",
    "    return \"generator\"\n",
    "\n",
    "# Build workflow\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"generator\", generator)\n",
    "workflow.add_node(\"evaluator\", evaluator)\n",
    "workflow.add_edge(START, \"generator\")\n",
    "workflow.add_edge(\"generator\", \"evaluator\")\n",
    "workflow.add_conditional_edges(\"evaluator\", should_continue, [\"generator\", END])\n",
    "\n",
    "app = workflow.compile()\n",
    "```\n",
    "\n",
    "### Agent Implementation\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "@tool\n",
    "def calculate(expr: str) -> str:\n",
    "    \"\"\"Calculate mathematical expression.\"\"\"\n",
    "    return str(eval(expr))\n",
    "\n",
    "tools = [search, calculate]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def agent_node(state: MessagesState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def tool_node(state: MessagesState):\n",
    "    results = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = {t.name: t for t in tools}[tool_call[\"name\"]]\n",
    "        result = tool.invoke(tool_call[\"args\"])\n",
    "        results.append(ToolMessage(content=result, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": results}\n",
    "\n",
    "def should_continue(state: MessagesState):\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# Build agent\n",
    "agent_graph = StateGraph(MessagesState)\n",
    "agent_graph.add_node(\"agent\", agent_node)\n",
    "agent_graph.add_node(\"tools\", tool_node)\n",
    "agent_graph.add_edge(START, \"agent\")\n",
    "agent_graph.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "agent_graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "agent_app = agent_graph.compile()\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73835ff",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### Workflow Best Practices\n",
    "\n",
    "1. **Keep Nodes Focused**\n",
    "   - Each node does one thing well\n",
    "   - Clear input-output contracts\n",
    "   - Easy to test independently\n",
    "\n",
    "2. **Use Type Hints**\n",
    "   ```python\n",
    "   class State(TypedDict):\n",
    "       input: str\n",
    "       result: str\n",
    "       metadata: dict\n",
    "   ```\n",
    "\n",
    "3. **Implement Quality Gates**\n",
    "   - Validate outputs at each stage\n",
    "   - Explicit pass/fail criteria\n",
    "   - Feedback loops for failures\n",
    "\n",
    "4. **Parallelize When Possible**\n",
    "   - Identify independent operations\n",
    "   - Use Send API for dynamic parallelization\n",
    "   - Aggregate results efficiently\n",
    "\n",
    "5. **Make Routing Explicit**\n",
    "   - Clear decision logic\n",
    "   - Enum types for routes\n",
    "   - Comprehensive edge cases\n",
    "\n",
    "### Agent Best Practices\n",
    "\n",
    "1. **Design Clear Tools**\n",
    "   ```python\n",
    "   @tool\n",
    "   def well_designed_tool(param: str) -> str:\n",
    "       \"\"\"\n",
    "       Clear description of what the tool does.\n",
    "       \n",
    "       Args:\n",
    "           param: Specific parameter description\n",
    "           \n",
    "       Returns:\n",
    "           Specific return value description\n",
    "       \"\"\"\n",
    "       return result\n",
    "   ```\n",
    "\n",
    "2. **Implement Safety Limits**\n",
    "   ```python\n",
    "   class AgentState(TypedDict):\n",
    "       messages: list\n",
    "       iterations: int\n",
    "       max_iterations: int  # Prevent infinite loops\n",
    "   ```\n",
    "\n",
    "3. **Add Human-in-the-Loop**\n",
    "   ```python\n",
    "   def should_continue(state):\n",
    "       if state[\"iterations\"] > 5:\n",
    "           return \"human_review\"  # Escalate complex cases\n",
    "       if state[\"messages\"][-1].tool_calls:\n",
    "           return \"tools\"\n",
    "       return END\n",
    "   ```\n",
    "\n",
    "4. **Log Agent Decisions**\n",
    "   - Track tool selections\n",
    "   - Record reasoning\n",
    "   - Monitor performance\n",
    "\n",
    "5. **Handle Failures Gracefully**\n",
    "   ```python\n",
    "   def tool_node(state):\n",
    "       try:\n",
    "           result = execute_tool(state)\n",
    "           return {\"messages\": [result]}\n",
    "       except Exception as e:\n",
    "           return {\"messages\": [ToolMessage(\n",
    "               content=f\"Error: {str(e)}\",\n",
    "               tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "           )]}\n",
    "   ```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60be35",
   "metadata": {},
   "source": [
    "## Common Pitfalls\n",
    "\n",
    "### Workflow Pitfalls\n",
    "\n",
    "‚ùå **Over-complicating Simple Tasks**\n",
    "```python\n",
    "# Don't do this for simple tasks\n",
    "def overly_complex_workflow(text):\n",
    "    analyzed = llm_analyze(text)\n",
    "    categorized = llm_categorize(analyzed)\n",
    "    processed = llm_process(categorized)\n",
    "    return llm_format(processed)\n",
    "\n",
    "# Just do this\n",
    "def simple_approach(text):\n",
    "    return llm.invoke(f\"Process this: {text}\")\n",
    "```\n",
    "\n",
    "‚ùå **Ignoring Error States**\n",
    "- Always handle LLM failures\n",
    "- Provide fallback paths\n",
    "- Don't assume perfect execution\n",
    "\n",
    "‚ùå **Tight Coupling**\n",
    "- Keep nodes independent\n",
    "- Avoid hidden dependencies\n",
    "- Make state explicit\n",
    "\n",
    "### Agent Pitfalls\n",
    "\n",
    "‚ùå **Infinite Loops**\n",
    "```python\n",
    "# Always add iteration limits\n",
    "class State(TypedDict):\n",
    "    iterations: int\n",
    "    max_iterations: int  # Required!\n",
    "\n",
    "def should_continue(state):\n",
    "    if state[\"iterations\"] >= state[\"max_iterations\"]:\n",
    "        return END  # Safety exit\n",
    "    # ... rest of logic\n",
    "```\n",
    "\n",
    "‚ùå **Too Many Tools to start with**\n",
    "- Limit to 5-10 tools per agent (Although langgraph can handle way too many but go iteratively)\n",
    "- Group related functions\n",
    "- Consider tool hierarchies\n",
    "\n",
    "‚ùå **Unclear Tool Descriptions**\n",
    "```python\n",
    "# Bad\n",
    "@tool\n",
    "def process(data):\n",
    "    \"\"\"Process data.\"\"\"  # Too vague!\n",
    "    \n",
    "# Good\n",
    "@tool\n",
    "def extract_email_addresses(text: str) -> list[str]:\n",
    "    \"\"\"Extract all email addresses from the given text.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to search for email addresses\n",
    "        \n",
    "    Returns:\n",
    "        List of email addresses found in the text\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "‚ùå **No Observability**\n",
    "- Implement logging\n",
    "- Track decision paths\n",
    "- Monitor tool usage\n",
    "- Measure performance\n",
    "\n",
    "---\n",
    "\n",
    "## Performance Considerations\n",
    "\n",
    "### Workflow Optimization\n",
    "\n",
    "1. **Minimize Sequential LLM Calls**\n",
    "   - Combine prompts when possible\n",
    "   - Use structured outputs to reduce steps\n",
    "\n",
    "2. **Cache Intermediate Results**\n",
    "   ```python\n",
    "   @lru_cache(maxsize=100)\n",
    "   def expensive_llm_call(input: str):\n",
    "       return llm.invoke(input)\n",
    "   ```\n",
    "\n",
    "3. **Batch When Possible**\n",
    "   - Process multiple inputs together\n",
    "   - Use LLM batch APIs\n",
    "\n",
    "### Agent Optimization\n",
    "\n",
    "1. **Limit Tool Calls**\n",
    "   - Set max iterations\n",
    "   - Encourage efficient tool use in prompts\n",
    "\n",
    "2. **Use Streaming**\n",
    "   ```python\n",
    "   for chunk in agent.stream(input, stream_mode=\"updates\"):\n",
    "       process_chunk(chunk)  # Handle results as they arrive\n",
    "   ```\n",
    "\n",
    "3. **Implement Caching**\n",
    "   - Cache tool results\n",
    "   - Store common patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6848a31",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Decision Checklist\n",
    "\n",
    "**Use Workflows if:**\n",
    "- [ ] Process steps are known\n",
    "- [ ] Path is mostly deterministic\n",
    "- [ ] Need strong auditability\n",
    "- [ ] Independent subtasks exist\n",
    "- [ ] Quality gates are clear\n",
    "\n",
    "**Use Agents if:**\n",
    "- [ ] Problem is exploratory\n",
    "- [ ] Tool choice is context-dependent\n",
    "- [ ] Need adaptive behavior\n",
    "- [ ] Feedback loops are essential\n",
    "- [ ] Path emerges from context\n",
    "\n",
    "**Use Hybrid if:**\n",
    "- [ ] Some parts are structured, others exploratory\n",
    "- [ ] Want workflow reliability with agent flexibility\n",
    "- [ ] Different user types need different approaches\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Experiment**: Start with simple workflows, evolve to agents\n",
    "2. **Measure**: Track performance, costs, and user satisfaction\n",
    "3. **Iterate**: Refine based on real-world usage\n",
    "4. **Scale**: Build on patterns that work\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de83927",
   "metadata": {},
   "source": [
    "## Attribution & License\n",
    "\n",
    "This guide adapts content from the official LangGraph documentation and tutorials.\n",
    "\n",
    "**Source**: LangGraph Official Documentation  \n",
    "**Copyright**: ¬© 2024 LangChain, Inc.  \n",
    "**License**: MIT License  \n",
    "**Original Materials**: [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "\n",
    "The original materials are licensed under the MIT License:\n",
    "- Full license text: [MIT License](https://github.com/langchain-ai/langgraph/blob/main/LICENSE)\n",
    "- Permission granted to use, copy, modify, and distribute with attribution\n",
    "\n",
    "**Aparsoft's Adaptations**: This guide has been enhanced by Aparsoft Private Limited with additional examples, explanations, decision frameworks, and production insights specific to our developer community.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b598a58",
   "metadata": {},
   "source": [
    "## üìû Get Help & Connect\n",
    "\n",
    "### üéì Learning & Community\n",
    "- **YouTube:** [@aparsoft-ai](https://youtube.com/@aparsoft-ai) - Main tutorial channel\n",
    "- **Github:** [Join our community](https://github.com/aparsoft) - Check our repos and examples (aparsoft-tutorial-resources)\n",
    "- **GitHub Discussions:** Ask questions about the code\n",
    "- **LinkedIn:** [/company/aparsoft](https://linkedin.com/company/aparsoft) - Articles and tips\n",
    "- **X (formerly Twitter):** [@aparsoft](https://x.com/AparsoftPvtLtd) - Tutorials and updates\n",
    "\n",
    "---\n",
    "\n",
    "*Last Updated: October 2025*  \n",
    "*Version: 1.0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086bcf65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
